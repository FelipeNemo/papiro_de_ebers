"""
Teste do Sistema PubMedBERT com Cache Inteligente
Fase 3: Teste de performance e otimizaÃ§Ã£o
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.cached_pubmedbert_search import CachedPubMedBERTSearch
from src.core.config import SNOMED_DATA_PATH
import time
import json

def test_cached_system():
    """Testa sistema com cache"""
    print("ğŸ§ª Teste do Sistema PubMedBERT com Cache Inteligente")
    print("=" * 70)
    
    try:
        # Inicializa sistema
        print("ğŸš€ Inicializando sistema com cache...")
        cached_search = CachedPubMedBERTSearch(cache_size=500)
        
        # Carrega modelo e Ã­ndice
        print("\nğŸ”¬ Carregando modelo e Ã­ndice...")
        cached_search.load_model()
        
        if not cached_search.load_index("data/snomed_pubmedbert_large_index"):
            print("âŒ Ãndice nÃ£o encontrado. Execute build_large_pubmedbert_index.py primeiro")
            return False
            
        print("âœ… Sistema carregado!")
        
        # Teste 1: Consultas Ãºnicas (cache miss)
        print("\n1ï¸âƒ£ Teste: Consultas Ãºnicas (cache miss)")
        unique_queries = [
            "dor no peito",
            "falta de ar",
            "diabetes tipo 2",
            "hipertensÃ£o arterial",
            "pneumonia"
        ]
        
        for i, query in enumerate(unique_queries, 1):
            print(f"\n   {i}. Buscando: '{query}'")
            result = cached_search.search_with_cache(query, top_k=3)
            
            print(f"      â±ï¸ Tempo: {result['search_time']:.3f}s")
            print(f"      ğŸ“Š Resultados: {len(result['results'])}")
            print(f"      ğŸ¯ Fonte: {result['source']}")
            print(f"      ğŸ’¾ Cache hit: {result['cache_hit']}")
            
            for j, concept in enumerate(result['results'][:2]):
                print(f"         {j+1}. {concept['term']} (score: {concept['similarity_score']:.3f})")
        
        # Teste 2: Consultas repetidas (cache hit)
        print("\n2ï¸âƒ£ Teste: Consultas repetidas (cache hit)")
        print("   Repetindo as mesmas consultas...")
        
        for i, query in enumerate(unique_queries, 1):
            print(f"\n   {i}. Buscando novamente: '{query}'")
            result = cached_search.search_with_cache(query, top_k=3)
            
            print(f"      â±ï¸ Tempo: {result['search_time']:.3f}s")
            print(f"      ğŸ¯ Fonte: {result['source']}")
            print(f"      ğŸ’¾ Cache hit: {result['cache_hit']}")
        
        # Teste 3: Consultas similares
        print("\n3ï¸âƒ£ Teste: Consultas similares")
        similar_query = "dor torÃ¡cica"
        similar_queries = cached_search.get_similar_queries(similar_query, threshold=0.5)
        
        print(f"   Query: '{similar_query}'")
        print(f"   ğŸ“Š Consultas similares encontradas: {len(similar_queries)}")
        for sim in similar_queries[:3]:
            print(f"      - {sim['query']} (similaridade: {sim['similarity']:.2f})")
        
        # Teste 4: Consultas populares
        print("\n4ï¸âƒ£ Teste: Consultas populares")
        popular_queries = cached_search.get_popular_queries(5)
        print(f"   ğŸ“Š Consultas populares: {len(popular_queries)}")
        for pop in popular_queries:
            print(f"      - {pop['query']} (especialidade: {pop['specialty']})")
        
        # Teste 5: Benchmark
        print("\n5ï¸âƒ£ Teste: Benchmark de Performance")
        benchmark_queries = unique_queries * 2  # 10 consultas
        benchmark_results = cached_search.benchmark_cache(benchmark_queries, iterations=2)
        
        # EstatÃ­sticas finais
        print("\nğŸ“Š EstatÃ­sticas Finais do Cache:")
        cache_stats = cached_search.get_cache_stats()
        print(f"   ğŸ’¾ Tamanho do cache: {cache_stats['cache_size']}/{cache_stats['max_size']}")
        print(f"   ğŸ“ˆ Hit rate: {cache_stats['hit_rate']:.1%}")
        print(f"   âœ… Hits: {cache_stats['hits']}")
        print(f"   âŒ Misses: {cache_stats['misses']}")
        print(f"   ğŸ—‘ï¸ Evictions: {cache_stats['evictions']}")
        print(f"   ğŸ”¢ Total queries: {cache_stats['total_queries']}")
        
        # Salva relatÃ³rio
        cached_search.export_cache_report("data/cache/test_cache_report.json")
        
        print("\nâœ… Sistema com cache funcionando perfeitamente!")
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_batch_processing():
    """Testa processamento em lote"""
    print("\nğŸ”„ Teste: Processamento em Lote")
    print("=" * 50)
    
    try:
        cached_search = CachedPubMedBERTSearch(cache_size=200)
        cached_search.load_model()
        cached_search.load_index("data/snomed_pubmedbert_large_index")
        
        # Lista de consultas para teste
        batch_queries = [
            "infarto do miocÃ¡rdio",
            "diabetes mellitus",
            "hipertensÃ£o arterial",
            "pneumonia",
            "insuficiÃªncia cardÃ­aca",
            "infarto do miocÃ¡rdio",  # Repetida para testar cache
            "diabetes mellitus",     # Repetida para testar cache
            "asma brÃ´nquica",
            "gastrite",
            "hepatite"
        ]
        
        print(f"ğŸ”„ Processando {len(batch_queries)} consultas em lote...")
        start_time = time.time()
        
        results = cached_search.search_batch(batch_queries, top_k=3)
        
        batch_time = time.time() - start_time
        
        print(f"\nğŸ“Š Resultados do Lote:")
        print(f"   â±ï¸ Tempo total: {batch_time:.3f}s")
        print(f"   ğŸš€ Velocidade: {len(batch_queries)/batch_time:.1f} consultas/segundo")
        
        # Analisa resultados
        cache_hits = sum(1 for r in results if r['cache_hit'])
        hit_rate = cache_hits / len(results)
        
        print(f"   ğŸ’¾ Cache hits: {cache_hits}/{len(results)} ({hit_rate:.1%})")
        
        # Mostra alguns resultados
        print(f"\nğŸ“‹ Exemplos de Resultados:")
        for i, result in enumerate(results[:3]):
            query = result['query']
            source = result['source']
            results_count = len(result['results'])
            print(f"   {i+1}. '{query}' -> {results_count} resultados ({source})")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no processamento em lote: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ¥ Teste do Sistema PubMedBERT com Cache Inteligente")
    print("=" * 70)
    
    # Teste principal
    success = test_cached_system()
    
    if success:
        # Teste de processamento em lote
        batch_success = test_batch_processing()
        
        print("\n" + "=" * 70)
        print("ğŸ“‹ Resumo dos Testes:")
        print(f"   âœ… Sistema com cache: {'PASSOU' if success else 'FALHOU'}")
        print(f"   âœ… Processamento em lote: {'PASSOU' if batch_success else 'FALHOU'}")
        
        if success and batch_success:
            print("\nğŸ‰ FASE 3 CONCLUÃDA!")
            print("âœ… Cache inteligente implementado")
            print("ğŸš€ Performance otimizada")
            print("ğŸ”¬ Pronto para Fase 4: Fine-tuning")
        else:
            print("\nâš ï¸ Alguns testes falharam")
    else:
        print("\nâŒ Falha nos testes principais")
